{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiDAR-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, AveragePooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import pcl\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResContextBlock(tf.keras.Model):\n",
    "    def __init__(self, out_filters):\n",
    "        super(ResContextBlock, self).__init__()\n",
    "        self.conv1 = Conv2D(out_filters, kernel_size=(1, 1), strides=1)\n",
    "        self.act1 = LeakyReLU()\n",
    "\n",
    "        self.conv2 = Conv2D(out_filters, kernel_size=(3,3), padding='same')\n",
    "        self.act2 = LeakyReLU()\n",
    "        self.bn1 = BatchNormalization()\n",
    "\n",
    "        self.conv3 = Conv2D(out_filters, kernel_size=(3,3), dilation_rate=2, padding='same')\n",
    "        self.act3 = LeakyReLU()\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        shortcut = self.conv1(x)\n",
    "        shortcut = self.act1(shortcut)\n",
    "\n",
    "        resA = self.conv2(shortcut)\n",
    "        resA = self.act2(resA)\n",
    "        resA1 = self.bn1(resA)\n",
    "\n",
    "        resA = self.conv3(resA1)\n",
    "        resA = self.act3(resA)\n",
    "        resA2 = self.bn2(resA)\n",
    "\n",
    "        output = shortcut + resA2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(tf.keras.Model):\n",
    "    def __init__(self, out_filters, dropout_rate, kernel_size=(3, 3), stride=1,\n",
    "                 pooling=True, drop_out=True):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.pooling = pooling\n",
    "        self.drop_out = drop_out\n",
    "        self.conv1 = Conv2D(out_filters, kernel_size=(1, 1), strides=stride)\n",
    "        self.act1 = LeakyReLU()\n",
    "\n",
    "        self.conv2 = Conv2D(out_filters, kernel_size=(3, 3), padding='same')\n",
    "        self.act2 = LeakyReLU()\n",
    "        self.bn1 = BatchNormalization()\n",
    "\n",
    "        self.conv3 = Conv2D(out_filters, kernel_size=(3,3),dilation_rate=2, padding='same')\n",
    "        self.act3 = LeakyReLU()\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "        self.conv4 = Conv2D(out_filters, kernel_size=(2, 2), dilation_rate=2, padding='same')\n",
    "        self.act4 = LeakyReLU()\n",
    "        self.bn3 = BatchNormalization()\n",
    "\n",
    "        self.conv5 = Conv2D(out_filters, kernel_size=(1, 1))\n",
    "        self.act5 = LeakyReLU()\n",
    "        self.bn4 = BatchNormalization()\n",
    "\n",
    "        if pooling:\n",
    "            self.dropout = Dropout(dropout_rate)\n",
    "            self.pool = AveragePooling2D(pool_size=kernel_size, strides=2, padding='same')\n",
    "        else:\n",
    "            self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        shortcut = self.conv1(x)\n",
    "        shortcut = self.act1(shortcut)\n",
    "\n",
    "        resA = self.conv2(x)\n",
    "        resA = self.act2(resA)\n",
    "        resA1 = self.bn1(resA)\n",
    "\n",
    "        resA = self.conv3(resA1)\n",
    "        resA = self.act3(resA)\n",
    "        resA2 = self.bn2(resA)\n",
    "\n",
    "        resA = self.conv4(resA2)\n",
    "        resA = self.act4(resA)\n",
    "        resA3 = self.bn3(resA)\n",
    "\n",
    "        concat = tf.concat((resA1,resA2,resA3),axis=-1)\n",
    "        resA = self.conv5(concat)\n",
    "        resA = self.act5(resA)\n",
    "        resA = self.bn4(resA)\n",
    "        resA = shortcut + resA\n",
    "\n",
    "\n",
    "        if self.pooling:\n",
    "            if self.drop_out:\n",
    "                resB = self.dropout(resA)\n",
    "            else:\n",
    "                resB = resA\n",
    "            resB = self.pool(resB)\n",
    "            return resB, resA\n",
    "        else:\n",
    "            if self.drop_out:\n",
    "                resB = self.dropout(resA)\n",
    "            else:\n",
    "                resB = resA\n",
    "            return resB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(tf.keras.Model):\n",
    "    def __init__(self, out_filters, dropout_rate, drop_out=True):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.drop_out = drop_out\n",
    "        self.out_filters = out_filters\n",
    "\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "        self.conv1 = Conv2D(out_filters, kernel_size=(3,3), padding='same')\n",
    "        self.act1 = LeakyReLU()\n",
    "        self.bn1 = BatchNormalization()\n",
    "\n",
    "        self.conv2 = Conv2D(out_filters, kernel_size=(3,3),dilation_rate=2, padding='same')\n",
    "        self.act2 = LeakyReLU()\n",
    "        self.bn2 = BatchNormalization()\n",
    "\n",
    "        self.conv3 = Conv2D(out_filters, kernel_size=(2,2), dilation_rate=2,padding='same')\n",
    "        self.act3 = LeakyReLU()\n",
    "        self.bn3 = BatchNormalization()\n",
    "\n",
    "\n",
    "        self.conv4 = Conv2D(out_filters,kernel_size=(1,1))\n",
    "        self.act4 = LeakyReLU()\n",
    "        self.bn4 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, skip):\n",
    "        upA = tf.nn.depth_to_space(x,2)\n",
    "        if self.drop_out:\n",
    "            upA = self.dropout1(upA)\n",
    "\n",
    "        upB = tf.concat((upA,skip),axis=-1)\n",
    "        if self.drop_out:\n",
    "            upB = self.dropout2(upB)\n",
    "\n",
    "        upE = self.conv1(upB)\n",
    "        upE = self.act1(upE)\n",
    "        upE1 = self.bn1(upE)\n",
    "\n",
    "        upE = self.conv2(upE1)\n",
    "        upE = self.act2(upE)\n",
    "        upE2 = self.bn2(upE)\n",
    "\n",
    "        upE = self.conv3(upE2)\n",
    "        upE = self.act3(upE)\n",
    "        upE3 = self.bn3(upE)\n",
    "\n",
    "        concat = tf.concat((upE1,upE2,upE3),axis=-1)\n",
    "        upE = self.conv4(concat)\n",
    "        upE = self.act4(upE)\n",
    "        upE = self.bn4(upE)\n",
    "        if self.drop_out:\n",
    "            upE = self.dropout3(upE)\n",
    "\n",
    "        return upE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 4)]   0         \n",
      "_________________________________________________________________\n",
      "res_context_block (ResContex (None, None, None, 32)    18912     \n",
      "_________________________________________________________________\n",
      "res_context_block_1 (ResCont (None, None, None, 32)    19808     \n",
      "_________________________________________________________________\n",
      "res_context_block_2 (ResCont (None, None, None, 32)    19808     \n",
      "_________________________________________________________________\n",
      "res_block (ResBlock)         ((None, None, None, 64),  87360     \n",
      "_________________________________________________________________\n",
      "res_block_1 (ResBlock)       ((None, None, None, 128), 346752    \n",
      "_________________________________________________________________\n",
      "res_block_2 (ResBlock)       ((None, None, None, 128), 428672    \n",
      "_________________________________________________________________\n",
      "res_block_3 (ResBlock)       ((None, None, None, 256), 1381632   \n",
      "_________________________________________________________________\n",
      "res_block_4 (ResBlock)       (None, None, None, 256)   1709312   \n",
      "_________________________________________________________________\n",
      "up_block (UpBlock)           (None, None, None, 128)   633344    \n",
      "_________________________________________________________________\n",
      "up_block_1 (UpBlock)         (None, None, None, 128)   449024    \n",
      "_________________________________________________________________\n",
      "up_block_2 (UpBlock)         (None, None, None, 64)    158976    \n",
      "_________________________________________________________________\n",
      "up_block_3 (UpBlock)         (None, None, None, 32)    40064     \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, None, None, 3)     99        \n",
      "=================================================================\n",
      "Total params: 5,293,763\n",
      "Trainable params: 5,283,907\n",
      "Non-trainable params: 9,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = [None,None,4]\n",
    "# Input shape kitti dataset\n",
    "#INPUT_SHAPE = [2048,64,5]\n",
    "# input shape of bugalog data\n",
    "#INPUT_SHAPE = [1024,16,4]\n",
    "# min input shape\n",
    "#INPUT_SHAPE = [16,16,5]\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_layer = Input(shape=INPUT_SHAPE)\n",
    "x = ResContextBlock(32)(input_layer)\n",
    "x = ResContextBlock(32)(x)\n",
    "x = ResContextBlock(32)(x)\n",
    "x,resBlock1 = ResBlock(64, 0.2, pooling=True, drop_out=False)(x)\n",
    "\n",
    "# NOTE evetnuell resBlock1 tiefe verdoppeln um genauigkeit zu erhöhen\n",
    "x,resBlock2 = ResBlock(128, 0.2, pooling=True)(x)\n",
    "x,resBlock3 = ResBlock(128, 0.2, pooling=True)(x)\n",
    "x,resBlock4 = ResBlock(256, 0.2, pooling=True)(x)\n",
    "\n",
    "x = ResBlock(256, 0.2, pooling=False)(x)\n",
    "\n",
    "x = UpBlock(128, 0.2)(x,resBlock4)\n",
    "x = UpBlock(128, 0.2)(x,resBlock3)\n",
    "x = UpBlock(64, 0.2)(x,resBlock2)\n",
    "x = UpBlock(32, 0.2, drop_out=False)(x,resBlock1)\n",
    "\n",
    "logits = Conv2D(3, kernel_size=(1, 1), activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=logits)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.models.save_model(model, \"test\", save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize = 4 # für 64er pc => BatchSize=4 #für 16er pc & 5,xMill. Param => 32 \n",
    "Epochs = 10 # 15 für 80% accuracy\n",
    "LearningRate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserscan import LaserScan, SemLaserScan\n",
    "#from laserscanvis import LaserScanVis\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate color map and lookup tables\n",
    "\n",
    "# Load configuration file\n",
    "CFG = yaml.safe_load(open('../config/semantic-kitti_GroundObject.yaml','r'))\n",
    "\n",
    "# Read kitti classes to color dictionary from configuration\n",
    "KittiToColorDict = CFG['color_map']\n",
    "\n",
    "# Read kitti to master project classes dictionary from configuration\n",
    "KittiToProjectDict = CFG['learning_map']\n",
    "\n",
    "# Read master project to kitti dictionary from configuration\n",
    "ProjectToKittiDict = CFG['learning_map_inv']\n",
    "\n",
    "# Create lookup table for kitti classes to color\n",
    "maxkeyColor = max(KittiToColorDict.keys()) + 100 # +100 hack making lut bigger in case there are unknown labels\n",
    "KittiToColor_LUT = np.zeros((maxkeyColor, 3), dtype=np.uint8)\n",
    "KittiToColor_LUT[list(KittiToColorDict.keys())] = list(KittiToColorDict.values())\n",
    "\n",
    "# Create lookup table for kitti classes to master project classes\n",
    "maxkey = max(KittiToProjectDict.keys()) + 100 # +100 hack making lut bigger in case there are unknown labels \n",
    "maxvalue = max(KittiToProjectDict.values())\n",
    "KittiToProject_LUT = np.zeros((maxkey), dtype=np.int32)\n",
    "KittiToProject_LUT[list(KittiToProjectDict.keys())] = list(KittiToProjectDict.values())\n",
    "\n",
    "# Create lookup table for master project classes to kitti classes\n",
    "maxkeyInv = max(ProjectToKittiDict.keys()) + 100 # +100 hack making lut bigger in case there are unknown labels\n",
    "ProjectToKitti_LUT = np.zeros((maxkeyInv), dtype=np.int32)\n",
    "ProjectToKitti_LUT[list(ProjectToKittiDict.keys())] = list(ProjectToKittiDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSampleArrayFromPointCloud (PointCloud, sample_path):\n",
    "    # Load point cloud from bin\n",
    "    PointCloud.open_scan(sample_path)\n",
    "    \n",
    "    xyz = PointCloud.proj_xyz.copy()\n",
    "    # Get intensity and range from point cloud\n",
    "    Intensity = PointCloud.proj_remission.copy()\n",
    "    #Intensity = Intensity * 0.8\n",
    "    #Intensity[Intensity < 0] = -1\n",
    "    #Range = PointCloud.proj_range.copy()\n",
    "    \n",
    "    # Expand dimensions to enable concatenate\n",
    "    Intensity = np.expand_dims(Intensity,axis=2)\n",
    "    #Range = np.expand_dims(Range,axis=2)\n",
    "    \n",
    "    # Concatenate intensity and range\n",
    "    xyzi = np.concatenate((xyz, Intensity),axis=2)\n",
    "    xyzi = np.swapaxes(xyzi,0,1)\n",
    "    return xyzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSampleArrayFromPointCloud_pcd (PointCloud, sample_path):\n",
    "    # Load point cloud from pcd\n",
    "    cloud = pcl.load_XYZI(sample_path)\n",
    "    cloud = cloud.to_array()\n",
    "    # Get points and intensity (remission) from pcd point cloud\n",
    "    points = cloud[:, 0:3]    # get xyz\n",
    "    \n",
    "    #points[:,2] = points[:,2] - 1.13\n",
    "    #camera 1,90\n",
    "    #kitty 1,73\n",
    "    #camera zu top +0,53\n",
    "    #top 2,43\n",
    "    #top zu front -1,83\n",
    "    #front 0,6\n",
    "    #front zu kitti 1,13\n",
    "    #top zu kitti -0,7\n",
    "    \n",
    "    remissions = cloud[:, 3]/255 #normal remissions\n",
    "    \n",
    "    # Set points and remission to PointCloud\n",
    "    PointCloud.set_points(points, remissions)\n",
    "    \n",
    "    xyz = PointCloud.proj_xyz.copy()\n",
    "    xyz[:,:,2] = xyz[:,:,2] -1.13 #+0.7 #- 1.13\n",
    "    \n",
    "    # Get intensity and range from point cloud\n",
    "    Intensity = PointCloud.proj_remission.copy()\n",
    "    #Range = PointCloud.proj_range.copy()\n",
    "\n",
    "    #remissions max 100:\n",
    "    #Intensity_orig = Intensity.copy()\n",
    "    #print(Intensity.shape)\n",
    "    #print(np.max(Intensity))\n",
    "    #Intensity[Intensity > 100] = -1 # not reflective elements\n",
    "    #Intensity[Intensity <= 100] = -1 # reflective elemtns\n",
    "    #Intensity = Intensity/np.max(Intensity)\n",
    "    #Intensity[Intensity < 0] = -1\n",
    "    #print(np.max(Intensity))\n",
    "    #print(np.min(Intensity))\n",
    "    \n",
    "    #Range[Intensity_orig > 100] = -1# not reflective\n",
    "    #Range[Intensity_orig <= 100] = -1 # reflective\n",
    "    \n",
    "    # Expand dimensions to enable concatenate\n",
    "    Intensity = np.expand_dims(Intensity,axis=2)\n",
    "    #Range = np.expand_dims(Range,axis=2)\n",
    "    \n",
    "    # Concatenate intensity and range\n",
    "    xyzi = np.concatenate((xyz, Intensity),axis=2)\n",
    "    xyzi = np.swapaxes(xyzi,0,1)\n",
    "    return xyzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabelArrayFromPointCloud(PointCloud, label_path):\n",
    "    # Load point cloud from bin\n",
    "    PointCloud.open_label(label_path)\n",
    "    \n",
    "    # Get labels from point cloud\n",
    "    Labels = PointCloud.proj_sem_label.copy()\n",
    "    \n",
    "    # Map kitti classes to project classes\n",
    "    Labels = KittiToProject_LUT[Labels]\n",
    "    Labels = np.swapaxes(Labels,0,1)\n",
    "    Labels = tf.keras.utils.to_categorical(Labels,num_classes=maxvalue+1)\n",
    "    return Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PointCloudGenerator(sample_paths, label_paths, batch_size, random=True): #add , pointcloud_size):\n",
    "    \"\"\"\n",
    "    sample_paths = [sample_path1, sample_path2, ...]\n",
    "    label_paths = [label_path1, label_path2, ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    if random == True:\n",
    "        sample_paths, label_paths = shuffle(sample_paths, label_paths, random_state=42)\n",
    "        \n",
    "    num_samples = len(sample_paths)\n",
    "\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size <= num_samples]\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            # Get the samples + paths you'll use in this batch\n",
    "            batch_sample_paths = sample_paths[offset:offset+batch_size]\n",
    "            batch_label_paths = label_paths[offset:offset+batch_size]\n",
    "            \n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "\n",
    "            # For each example\n",
    "            for batch_sample,_ in enumerate(batch_sample_paths):\n",
    "                \n",
    "                # Load points (X) and labels (y)\n",
    "                PointCloud = SemLaserScan(20, KittiToColorDict, project=True, W=2048, H=64)\n",
    "                \n",
    "                current_sample_path = batch_sample_paths[batch_sample]\n",
    "                current_label_path = batch_label_paths[batch_sample]\n",
    "                \n",
    "                current_sample = getSampleArrayFromPointCloud (PointCloud, current_sample_path)\n",
    "                current_sample = current_sample[0::2,0::4]\n",
    "                \n",
    "                current_label = getLabelArrayFromPointCloud(PointCloud, current_label_path)\n",
    "                current_label = current_label[0::2,0::4]\n",
    "                \n",
    "                # Add example to arrays\n",
    "                X_train.append(current_sample)\n",
    "                y_train.append(current_label)\n",
    "\n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "\n",
    "            # The generator-y part: yield the next training batch            \n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labeled data path\n",
    "PATH = '/data/kitti_data/dataset/sequences/'\n",
    "# Get all labeled sequences\n",
    "sequences = [PATH + i for i in sorted(os.listdir(PATH))]\n",
    "\n",
    "sample_paths = []\n",
    "label_paths = []\n",
    "\n",
    "# foreach labeled sequence -> get sample and lable path\n",
    "for i in sequences:\n",
    "    sample = i + '/velodyne/'\n",
    "    label = i + '/labels/'\n",
    "    for s in sorted(os.listdir(sample)):\n",
    "        sample_paths.append(sample + s)\n",
    "    for s in sorted(os.listdir(label)):\n",
    "        label_paths.append(label + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle paths and split them into training & validation paths\n",
    "train_sample_paths, val_sample_paths, train_label_paths, val_label_paths = train_test_split(sample_paths, label_paths, train_size=0.8, random_state=42)\n",
    "val_sample_paths, eval_sample_paths, val_label_paths, eval_label_paths = train_test_split(val_sample_paths, val_label_paths, train_size=0.75, random_state=42)\n",
    "\n",
    "# Create training and validation generators\n",
    "datagen = PointCloudGenerator(train_sample_paths, train_label_paths, BatchSize)\n",
    "val_gen = PointCloudGenerator(val_sample_paths, val_label_paths, BatchSize)\n",
    "eval_gen = PointCloudGenerator(eval_sample_paths, eval_label_paths, BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = Adam(learning_rate = LearningRate)\n",
    "# Configure model for training\n",
    "model.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer=Optimizer,\n",
    "metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 4640 steps, validate for 870 steps\n",
      "Epoch 1/10\n",
      "4640/4640 [==============================] - 1329s 286ms/step - loss: 0.3251 - accuracy: 0.8815 - val_loss: 0.2038 - val_accuracy: 0.9299\n",
      "Epoch 2/10\n",
      "4640/4640 [==============================] - 1326s 286ms/step - loss: 0.1922 - accuracy: 0.9345 - val_loss: 0.1740 - val_accuracy: 0.9407\n",
      "Epoch 3/10\n",
      "4640/4640 [==============================] - 1335s 288ms/step - loss: 0.1699 - accuracy: 0.9423 - val_loss: 0.1587 - val_accuracy: 0.9462\n",
      "Epoch 4/10\n",
      "4640/4640 [==============================] - 1336s 288ms/step - loss: 0.1573 - accuracy: 0.9466 - val_loss: 0.1481 - val_accuracy: 0.9499\n",
      "Epoch 5/10\n",
      "4640/4640 [==============================] - 1338s 288ms/step - loss: 0.1487 - accuracy: 0.9495 - val_loss: 0.1411 - val_accuracy: 0.9523\n",
      "Epoch 6/10\n",
      "4640/4640 [==============================] - 1352s 291ms/step - loss: 0.1421 - accuracy: 0.9517 - val_loss: 0.1355 - val_accuracy: 0.9541\n",
      "Epoch 7/10\n",
      "4640/4640 [==============================] - 1346s 290ms/step - loss: 0.1366 - accuracy: 0.9535 - val_loss: 0.1310 - val_accuracy: 0.9555\n",
      "Epoch 8/10\n",
      "4640/4640 [==============================] - 1340s 289ms/step - loss: 0.1320 - accuracy: 0.9549 - val_loss: 0.1279 - val_accuracy: 0.9565\n",
      "Epoch 9/10\n",
      "4640/4640 [==============================] - 1345s 290ms/step - loss: 0.1279 - accuracy: 0.9562 - val_loss: 0.1235 - val_accuracy: 0.9578\n",
      "Epoch 10/10\n",
      "4640/4640 [==============================] - 1339s 289ms/step - loss: 0.1242 - accuracy: 0.9574 - val_loss: 0.1198 - val_accuracy: 0.9590\n"
     ]
    }
   ],
   "source": [
    "TrainingHistory = model.fit(\n",
    "    x=datagen,\n",
    "    epochs=Epochs,\n",
    "    verbose=1,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch = math.ceil(len(train_sample_paths)/BatchSize),\n",
    "    validation_steps = math.ceil(len(val_sample_paths)/BatchSize)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('../weights/model_weights_IR_16_1024.h5')\n",
    "#model.save_weights('../weights/model_weights_IR_64_2048.h5')\n",
    "model.save_weights('../weights/model_weights_xyzi_16_1024_GroundDetection_inklTerain.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "#model.save(\"../NewGroundDetectionXYZI\")\n",
    "#model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate network general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('../weights/model_weights_xyzi_16_1024.h5')\n",
    "#model.load_weights('../weights/model_weights_IR_64_2048.h5')\n",
    "Evaluation = model.evaluate(eval_gen, steps=math.ceil(len(eval_sample_paths)/BatchSize))\n",
    "print(Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate network visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reduced model weights\n",
    "model.load_weights('../weights/model_weights_xyzi_16_1024_GroundDetection_inklTerain.h5')\n",
    "\n",
    "# Load full model weights\n",
    "#model.load_weights('../weights/model_weights_IR_64_2048.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictionToImage(Prediction):\n",
    "    # Map masterproject classes to kitti classes \n",
    "    Prediction = ProjectToKitti_LUT[Prediction]\n",
    "    # Map kitti classes to colors\n",
    "    Image = KittiToColor_LUT[Prediction]\n",
    "    Image = np.swapaxes(Image,0,1)\n",
    "    Image = Image[...,[2,1,0]]\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 64, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Define path of test PoinCloud\n",
    "TestPath = '/data/kitti_data/dataset/sequences'\n",
    "CurrentTestPoinCloudPath = TestPath + '/04/velodyne/000008.bin'\n",
    "\n",
    "# Create test PointCloud\n",
    "TestPointCloud = SemLaserScan(20, KittiToColorDict, project=True, W=2048, H=64)\n",
    "\n",
    "# Create full sample array from PoinCloud\n",
    "CurrentTestSampleFull = getSampleArrayFromPointCloud (TestPointCloud, CurrentTestPoinCloudPath)\n",
    "print(CurrentTestSampleFull.shape)\n",
    "#print(np.min(CurrentTestSampleFull[:,:,2]))\n",
    "CurrentTestSampleFull = np.expand_dims(CurrentTestSampleFull, axis=0)\n",
    "\n",
    "# Create reduced sample array from full sample array\n",
    "#print(CurrentTestSampleFull.shape)\n",
    "CurrentTestSampleReduced = CurrentTestSampleFull[0::,0::2,0::4]\n",
    "#print(np.min(CurrentTestSampleReduced[0,:,:,2]))\n",
    "#print(CurrentTestSampleReduced.shape)\n",
    "\n",
    "# Predict full PointCloud\n",
    "PredictionFull = model.predict(CurrentTestSampleFull)\n",
    "PredictionFull = np.argmax(PredictionFull,axis=3)\n",
    "PredictionFull = PredictionFull.squeeze()\n",
    "\n",
    "# Predict reduced PointCloud\n",
    "PredictionReduced = model.predict(CurrentTestSampleReduced)\n",
    "PredictionReduced = np.argmax(PredictionReduced,axis=3)\n",
    "PredictionReduced = PredictionReduced.squeeze()\n",
    "\n",
    "# Create images of predictions\n",
    "PredictionFullImage = PredictionToImage(PredictionFull)\n",
    "PredictionReducedImage = PredictionToImage(PredictionReduced)\n",
    "\n",
    "# [optional] Spot special classes in image\n",
    "#ids = np.where((CurrentTestSampleReduced[0,:,:,2] < -5))\n",
    "#print(ids)\n",
    "#PredictionReducedImage[ids] = [255, 0, 0]\n",
    "#PredictionReducedImage = np.swapaxes(PredictionReducedImage,0,1)\n",
    "#PredictionFullImage = np.swapaxes(PredictionFullImage,0,1)\n",
    "\n",
    "# Show and save full prediction image\n",
    "fig = plt.figure()\n",
    "plt.imshow(PredictionFullImage)\n",
    "plt.show\n",
    "plt.imsave('../images/PredictionFull.png', PredictionFullImage)\n",
    "\n",
    "# Show and save reduced prediction image\n",
    "fig = plt.figure()\n",
    "plt.imshow(PredictionReducedImage)\n",
    "plt.show\n",
    "plt.imsave('../images/PredictionReduced.png', PredictionReducedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentTestLabelPath = TestPath + '/04/labels/000008.label'\n",
    "\n",
    "CurrentLabelFull = getLabelArrayFromPointCloud (TestPointCloud, CurrentTestLabelPath)\n",
    "CurrentLabelFull = np.expand_dims(CurrentLabelFull, axis=0)\n",
    "\n",
    "CurrentLabelReduced = CurrentLabelFull[0::,0::2,0::4]\n",
    "\n",
    "CurrentLabelFull = np.argmax(CurrentLabelFull,axis=3)\n",
    "CurrentLabelFull = CurrentLabelFull.squeeze()\n",
    "\n",
    "CurrentLabelReduced = np.argmax(CurrentLabelReduced,axis=3)\n",
    "CurrentLabelReduced = CurrentLabelReduced.squeeze()\n",
    "\n",
    "GroundTruthFullImage = PredictionToImage(CurrentLabelFull)\n",
    "GroundTruthReducedImage = PredictionToImage(CurrentLabelReduced)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(GroundTruthFullImage)\n",
    "plt.show\n",
    "plt.imsave('../images/GroundTruthFullImage.png', GroundTruthFullImage)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(GroundTruthReducedImage)\n",
    "plt.show\n",
    "plt.imsave('../images/GroundTruthReducedImage.png', GroundTruthReducedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create intensity histogram of full kitti data\n",
    "fig = plt.figure()\n",
    "print(CurrentTestSampleFull.shape)\n",
    "I = CurrentTestSampleFull[:,:,:,0].flatten()\n",
    "# print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')\n",
    "plt.title(\"Intensity histogram of full kitti data\")\n",
    "plt.show()\n",
    "\n",
    "# Create intensity histogram of reduced kitti data\n",
    "fig = plt.figure()\n",
    "I = CurrentTestSampleReduced[:,:,:,0].flatten()\n",
    "print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Intensity histogram of reduced kitti data\")\n",
    "plt.show()\n",
    "\n",
    "# Create range histogram of full kitti data\n",
    "fig = plt.figure()\n",
    "print(CurrentTestSampleFull.shape)\n",
    "I = CurrentTestSampleFull[:,:,:,1].flatten()\n",
    "# print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')\n",
    "plt.title(\"Range histogram of full kitti data\")\n",
    "plt.show()\n",
    "\n",
    "# Create range histogram of reduced kitti data\n",
    "fig = plt.figure()\n",
    "I = CurrentTestSampleReduced[:,:,:,1].flatten()\n",
    "print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Range histogram of reduced kitti data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict BugaLog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.704252\n",
      "-2.743859\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAAnCAYAAAAfDrO+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAILklEQVR4nO2dbYgdVxnHf3+zJjHVmo0xNZriJlIKQdDulpKolNLatA0lReiHxIKpVgqKxVc0ISD4ybaKSEFMxXeJsTVWGwIapLbfJLYbTZq+rNm20W5NTYNYXyrY4OOHcyY7e3fuvTN3Z+fl8vxguTPPOXPO/zxz5rlnzp05KzPDcRzHaT+vqVuA4ziOUw4e0B3HcYYED+iO4zhDggd0x3GcIcEDuuM4zpDgAd1xHGdIWFBAl3S9pClJ05J2lSXKcRzHKY4GfQ5d0hLgj8C1wAzwKLDDzJ4sT57jOI6Tl4WM0K8Aps3sWTP7L/AT4KZyZDmO4zhF6RvQJX1X0hlJJ1K2VcBeYJOkX0saJYzS37Z4Uh3HcZxe9J1ykXQl8C/gh2b2zmi7mxC8/wNMA6PACeAKM7uj4/jbgdvj7kSp6ktkxUSQ9srkZN88WXQ7bsXERM+0fnV25svaTmvIqq+X7iyS49NldW53O65oXU2l7rZ0+r3zvKbtecpI2/K0q0i+tJ5eFCmv87h+Zeeh0w8t46yZvblfplxz6JLGgEOpgD4FfBa4A7gVeAT4PoCZfblHOXMqG2/AOjJHpVz58mjNKmvcbJ49sXWWmdjS+Qf1UVadCyGvn8qoy+lPr/NRhv+z+mcvDUneIv0k73G9rpeyaGqfTbVx0swu75d/ZMB6LgJ+BdwDLAfWANuBD/Y70Eg5rrzz0ZeJLucrHUDHzZjsoinPWG1O2xIUUjJtCrqOSvFYm58/pSfJm6fz5e2g3QL/fD8YynnCOsvM9EuDEMqlUWT7vlufKYsJC3UkfXgyq0+l8/coKymnv2bLcX1m9dOC5zrPcanrBWb9sJAgnB48DVLOYp/zhKLVDBrQMbNzkj4BHAYuBO43syfmCZo75VIbvU/AbLDqFvgHLzvPsfkqnezo2OWQ9WXTaeo/Guw1WkoHwqouhCLk/cKx0n2fj8RneX3XL18Tz0E3BrkeYbaN3b+8bN4XRRNJ+mbewdRCplyuMrPTktYCj5jZpTnK+ScwlUtZs1gNnK1bxIC0VXtbdUN7tbdVN7RXe17db88zhz7oCP0gsBO4M34+mPO4qTzzQE1D0mNt1A3t1d5W3dBe7W3VDe3VXrbuPI8t7gd+C1wqaUbSbYRAfq2kk4QXi+4sS5DjOI4zGH1H6Ga2o0vSNSVrcRzHcRZA1Ytzfavi+sqirbqhvdrbqhvaq72tuqG92kvVPfBaLo7jOE6z8OVzHcdxhoRKAnrTl9mVdLGkhyU9JekJSZ+M9lVxrZqTqTVrUOCe2J7jksZr1r9E0u8lHYr76yUdibrvk7Q02pfF/emYPlaz7pWSDkh6Ovp+cxt8LunTsZ+ckLRf0vKm+rzbWkxFfSxpZ8x/UtLOmnR/JfaV45J+LmllKm131D0l6bqUvfLYk6U9lfY5SSZpddwv1+dmtqh/wBLgGWADsBQ4Bmxc7HoLalwLjMftNxCWBd4I3A3sivZdwF1xeyvwS8IrCZuAIzXr/wzwY8K7AgD3A9vj9l7gY3H748DeuL0duK9m3T8APhq3lwIrm+5zwhpGzwGvS/n61qb6HLgSGAdOpGyFfAysAp6Nn6Nxe7QG3VuAkbh9V0r3xhhXlgHrY7xZUlfsydIe7RcTXsT8E7B6MXxeRYfaDBxO7e8GdlfZqQfQ/CDhccwpYG20rSU8Rw9wL2Ht9yT/+Xw1aF0HPARcDRyKHeNsquOf93/sTJvj9kjMp5p0XxgDozrsjfY5IaA/Hy+0kejz65rsc2CsIzAW8jGwA7g3ZZ+TryrdHWkfAPbF7TkxJfF5nbEnSztwAHgXcIrZgF6qz6uYckkugIRGL7Mbb4kvA44AF5nZaYD4uSZma1Kbvg58Hvhf3H8T8HczOxf309rO647pL8f8dbABeAn4Xpwu+rakC2i4z83sBeCrwJ+B0wQfTtIOnycU9XEjfN/BRwgjW2iBbknbgBfM7FhHUqnaqwjoWYsQNPLRGkmvB34GfMrM/tEra4at8jZJuhE4Y2bptUB7aWuE7sgI4bb0m2Z2GfBvwu1/NxqhPc4330S4tX8rcAFwQ0bWJvq8H920NqoNkvYA54B9iSkjW2N0S1oB7AG+mJWcYRtYexUBfYYwd5SwDvhLBfUWQtJrCcF8n5k9EM1/VVirhvh5Jtqb0qb3AtsknSL8x6irCSP2lZKSl8bS2s7rjulvBP5WpeAUM8CMmR2J+wcIAb7pPn8/8JyZvWRmrwIPAO+hHT5PKOrjpvie+OPgjcAtFuciaL7udxAGAMfitboOOCrpLZSsvYqA/ihwSXwKYCnhh6GDFdSbG0kCvgM8ZWZfSyUla9bA3DVrDgIfir9QbwJeTm5hq8TMdpvZOjMbI/j1N2Z2C/AwcHMX3Ul7bo75axlpmdmLwPOSkkXdrgGepOE+J0y1bJK0IvabRHfjfZ6iqI8PA1skjcY7lC3RVimSrge+AGwzs1dSSQeB7fGJovXAJcDvaEjsMbPHzWyNmY3Fa3WG8BDGi5Tt84p+INhKeHLkGWBPFXUW1Pc+wu3MceAP8W8rYa7zIeBk/FwV8wv4RmzP48DlDWjDVcw+5bKB0KGngZ8Cy6J9edyfjukbatb8buCx6PdfEH7Nb7zPgS8BTxP+S9ePCE9XNNLnwH7CXP+rMZDcNoiPCXPW0/HvwzXpnibMKyfX6N5U/j1R9xRwQ8peeezJ0t6RforZH0VL9bm/Keo4jjMk+JuijuM4Q4IHdMdxnCHBA7rjOM6Q4AHdcRxnSPCA7jiOMyR4QHccxxkSPKA7juMMCR7QHcdxhoT/AyZ7vN7yk/DeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCDPATH = '../data/pcd_files/'\n",
    "current_pcd_path = PCDPATH + 'front_cloud_straße.pcd' #'top_cloud_git.pcd'\n",
    "\n",
    "PointCloud = SemLaserScan(20, KittiToColorDict, project=True, W=1440, H=16, fov_up=15, fov_down=-15.0)\n",
    "\n",
    "current_sample = getSampleArrayFromPointCloud_pcd(PointCloud, current_pcd_path)\n",
    "#print(current_sample.shape)\n",
    "#current_sample[:,:,2] = current_sample[:,:,2] -0.4#1.13 #+0.7 #- 1.13\n",
    "print(np.max(current_sample[:,:,2]))\n",
    "print(np.min(current_sample[:,:,2]))\n",
    "\n",
    "#current_sample = current_pcd\n",
    "current_sample = np.expand_dims(current_sample, axis=0)\n",
    "\n",
    "#current_sample = current_sample[0::,0::2,0::4]\n",
    "#current_sample[np.where(current_sample[:,:,:,0] > 0.4)] = [-1, -1]\n",
    "\n",
    "Prediction = model.predict(current_sample)\n",
    "\n",
    "Prediction = np.argmax(Prediction,axis=3)\n",
    "\n",
    "Prediction = Prediction.squeeze()\n",
    "\n",
    "BugaLogImage = PredictionToImage(Prediction)\n",
    "\n",
    "plt.imshow(BugaLogImage)\n",
    "plt.show\n",
    "plt.imsave('../images/BugaLogImage.png', BugaLogImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "I = current_sample[:,:,:,0].flatten()\n",
    "print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Intensity histogram of buga log data\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "R = current_sample[:,:,:,1].flatten()\n",
    "print(R.shape)\n",
    "hist = plt.hist(R, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Range histogram of buga log data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create result point cloud (unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 16, 4)\n",
      "(1440, 16, 4)\n",
      "(23040, 4)\n",
      "(14446, 4)\n"
     ]
    }
   ],
   "source": [
    "#### import pcl\n",
    "intensity = Prediction\n",
    "\n",
    "input_cloud = current_sample.squeeze()\n",
    "\n",
    "print(input_cloud.shape)\n",
    "cloud = input_cloud.copy()\n",
    "cloud[:,:,3]=Prediction\n",
    "#cloud=cloud[:,:,0:4]\n",
    "# überprüfen ob 0:4 oder 1:5\n",
    "print(cloud.shape)\n",
    "\n",
    "#print(input_cloud[1,1,:])\n",
    "#print(cloud[1,1,:])\n",
    "\n",
    "\n",
    "cloud = np.reshape(cloud, (cloud.shape[0]*cloud.shape[1], 4))\n",
    "\n",
    "print(cloud.shape)\n",
    "\n",
    "cloud = cloud[cloud[:,1]!= -1]\n",
    "\n",
    "print(cloud.shape)\n",
    "\n",
    "p = pcl.PointCloud_PointXYZI(cloud)\n",
    "\n",
    "pcl.save(p, './newfrontcloud_straße.pcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pptk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud = pcl.load_XYZI('./newcloud.pcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = Cloud.to_array()\n",
    "XYZ = points[:100:,0:3]\n",
    "XYZ = pptk.rand(100,3)\n",
    "\n",
    "print(XYZ.shape)\n",
    "v = pptk.viewer(XYZ)\n",
    "#v.attributes(points[:,3])\n",
    "#v.set(point_size=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
