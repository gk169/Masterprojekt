{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiDAR-Net train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import pcl\n",
    "import math\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from laserscan import LaserScan, SemLaserScan\n",
    "from model import LiDAR_Model\n",
    "from pointcloud_handling_jupyter import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 'xyzi' # ir xyz xyzi xyzir\n",
    "yaml_path = '../config/semantic-kitti_GroundObject.yaml' #'../config/semantic-kitti_GroundObject.yaml' OR '../config/semantic-kitti.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate color map and lookup tables\n",
    "\n",
    "# Load configuration file\n",
    "CFG = yaml.safe_load(open(yaml_path,'r'))\n",
    "\n",
    "# Read kitti classes to color dictionary from configuration\n",
    "KittiToColorDict = CFG['color_map']\n",
    "\n",
    "# Read kitti to master project classes dictionary from configuration\n",
    "KittiToProjectDict = CFG['learning_map']\n",
    "\n",
    "# Read master project to kitti dictionary from configuration\n",
    "ProjectToKittiDict = CFG['learning_map_inv']\n",
    "\n",
    "# Create lookup table for kitti classes to color\n",
    "maxkeyColor = max(KittiToColorDict.keys()) + 100 # +100 hack making lut bigger in case there are unknown labels\n",
    "KittiToColor_LUT = np.zeros((maxkeyColor, 3), dtype=np.uint8)\n",
    "KittiToColor_LUT[list(KittiToColorDict.keys())] = list(KittiToColorDict.values())\n",
    "\n",
    "# Create lookup table for kitti classes to master project classes\n",
    "maxkey = max(KittiToProjectDict.keys()) + 100 # +100 hack making lut bigger in case there are unknown labels \n",
    "maxvalue = max(KittiToProjectDict.values())\n",
    "KittiToProject_LUT = np.zeros((maxkey), dtype=np.int32)\n",
    "KittiToProject_LUT[list(KittiToProjectDict.keys())] = list(KittiToProjectDict.values())\n",
    "\n",
    "# Create lookup table for master project classes to kitti classes\n",
    "maxkeyInv = max(ProjectToKittiDict.keys()) + 100 # +100 hack making lut bigger in case there are unknown labels\n",
    "ProjectToKitti_LUT = np.zeros((maxkeyInv), dtype=np.int32)\n",
    "ProjectToKitti_LUT[list(ProjectToKittiDict.keys())] = list(ProjectToKittiDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 4)]   0         \n",
      "_________________________________________________________________\n",
      "res_context_block (ResContex (None, None, None, 32)    18912     \n",
      "_________________________________________________________________\n",
      "res_context_block_1 (ResCont (None, None, None, 32)    19808     \n",
      "_________________________________________________________________\n",
      "res_context_block_2 (ResCont (None, None, None, 32)    19808     \n",
      "_________________________________________________________________\n",
      "res_block (ResBlock)         ((None, None, None, 64),  87360     \n",
      "_________________________________________________________________\n",
      "res_block_1 (ResBlock)       ((None, None, None, 128), 346752    \n",
      "_________________________________________________________________\n",
      "res_block_2 (ResBlock)       ((None, None, None, 128), 428672    \n",
      "_________________________________________________________________\n",
      "res_block_3 (ResBlock)       ((None, None, None, 256), 1381632   \n",
      "_________________________________________________________________\n",
      "res_block_4 (ResBlock)       (None, None, None, 256)   1709312   \n",
      "_________________________________________________________________\n",
      "up_block (UpBlock)           (None, None, None, 128)   633344    \n",
      "_________________________________________________________________\n",
      "up_block_1 (UpBlock)         (None, None, None, 128)   449024    \n",
      "_________________________________________________________________\n",
      "up_block_2 (UpBlock)         (None, None, None, 64)    158976    \n",
      "_________________________________________________________________\n",
      "up_block_3 (UpBlock)         (None, None, None, 32)    40064     \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, None, None, 3)     99        \n",
      "=================================================================\n",
      "Total params: 5,293,763\n",
      "Trainable params: 5,283,907\n",
      "Non-trainable params: 9,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LiDAR_Model(len(layers), CFG['num_classes'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize = 4 # für 64er pc => BatchSize=4 #für 16er pc & 5,xMill. Param => 32 \n",
    "Epochs = 30 #TODO - mehr EPOCHS\n",
    "LearningRate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PointCloudGenerator(sample_paths, label_paths, batch_size, random=True): #add , pointcloud_size):\n",
    "    \"\"\"\n",
    "    sample_paths = [sample_path1, sample_path2, ...]\n",
    "    label_paths = [label_path1, label_path2, ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    if random == True:\n",
    "        sample_paths, label_paths = shuffle(sample_paths, label_paths, random_state=42)\n",
    "        \n",
    "    num_samples = len(sample_paths)\n",
    "\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size <= num_samples]\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            # Get the samples + paths you'll use in this batch\n",
    "            batch_sample_paths = sample_paths[offset:offset+batch_size]\n",
    "            batch_label_paths = label_paths[offset:offset+batch_size]\n",
    "            \n",
    "            # Initialise X_train and y_train arrays for this batch\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "\n",
    "            # For each example\n",
    "            for batch_sample,_ in enumerate(batch_sample_paths):\n",
    "                \n",
    "                # Load points (X) and labels (y)\n",
    "                PointCloud = SemLaserScan(20, KittiToColorDict, project=True, W=2048, H=64)\n",
    "                \n",
    "                current_sample_path = batch_sample_paths[batch_sample]\n",
    "                current_label_path = batch_label_paths[batch_sample]\n",
    "                \n",
    "                current_sample = getSampleArrayFromPointCloud (PointCloud, current_sample_path, layers)\n",
    "                current_sample = current_sample[0::2,0::4]\n",
    "                \n",
    "                current_label = getLabelArrayFromPointCloud(PointCloud, current_label_path, KittiToProject_LUT, maxvalue)\n",
    "                current_label = current_label[0::2,0::4]\n",
    "                \n",
    "                # Add example to arrays\n",
    "                X_train.append(current_sample)\n",
    "                y_train.append(current_label)\n",
    "\n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "\n",
    "            # The generator-y part: yield the next training batch            \n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labeled data path\n",
    "PATH = '/data/kitti_data/dataset/sequences/'\n",
    "# Get all labeled sequences\n",
    "sequences = [PATH + i for i in sorted(os.listdir(PATH))]\n",
    "\n",
    "sample_paths = []\n",
    "label_paths = []\n",
    "\n",
    "# foreach labeled sequence -> get sample and lable path\n",
    "for i in sequences:\n",
    "    sample = i + '/velodyne/'\n",
    "    label = i + '/labels/'\n",
    "    for s in sorted(os.listdir(sample)):\n",
    "        sample_paths.append(sample + s)\n",
    "    for s in sorted(os.listdir(label)):\n",
    "        label_paths.append(label + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle paths and split them into training & validation paths\n",
    "train_sample_paths, val_sample_paths, train_label_paths, val_label_paths = train_test_split(sample_paths, label_paths, train_size=0.8, random_state=42)\n",
    "val_sample_paths, eval_sample_paths, val_label_paths, eval_label_paths = train_test_split(val_sample_paths, val_label_paths, train_size=0.75, random_state=42)\n",
    "\n",
    "# Create training and validation generators\n",
    "datagen = PointCloudGenerator(train_sample_paths, train_label_paths, BatchSize)\n",
    "val_gen = PointCloudGenerator(val_sample_paths, val_label_paths, BatchSize)\n",
    "eval_gen = PointCloudGenerator(eval_sample_paths, eval_label_paths, BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = Adam(learning_rate = LearningRate)\n",
    "# Configure model for training\n",
    "model.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer=Optimizer,\n",
    "metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 4640 steps, validate for 870 steps\n",
      "Epoch 1/30\n",
      "4640/4640 [==============================] - 1355s 292ms/step - loss: 0.3223 - accuracy: 0.8811 - val_loss: 0.2081 - val_accuracy: 0.9279\n",
      "Epoch 2/30\n",
      "4640/4640 [==============================] - 1339s 289ms/step - loss: 0.1940 - accuracy: 0.9339 - val_loss: 0.1750 - val_accuracy: 0.9403\n",
      "Epoch 3/30\n",
      "4640/4640 [==============================] - 1339s 289ms/step - loss: 0.1714 - accuracy: 0.9420 - val_loss: 0.1599 - val_accuracy: 0.9459\n",
      "Epoch 4/30\n",
      "4640/4640 [==============================] - 1343s 289ms/step - loss: 0.1588 - accuracy: 0.9464 - val_loss: 0.1493 - val_accuracy: 0.9498\n",
      "Epoch 5/30\n",
      "4640/4640 [==============================] - 1343s 289ms/step - loss: 0.1497 - accuracy: 0.9494 - val_loss: 0.1413 - val_accuracy: 0.9523\n",
      "Epoch 6/30\n",
      "4640/4640 [==============================] - 1343s 289ms/step - loss: 0.1428 - accuracy: 0.9517 - val_loss: 0.1356 - val_accuracy: 0.9541\n",
      "Epoch 7/30\n",
      "4640/4640 [==============================] - 1344s 290ms/step - loss: 0.1372 - accuracy: 0.9535 - val_loss: 0.1312 - val_accuracy: 0.9555\n",
      "Epoch 8/30\n",
      "4640/4640 [==============================] - 1342s 289ms/step - loss: 0.1324 - accuracy: 0.9550 - val_loss: 0.1265 - val_accuracy: 0.9569\n",
      "Epoch 9/30\n",
      "4640/4640 [==============================] - 1342s 289ms/step - loss: 0.1283 - accuracy: 0.9563 - val_loss: 0.1224 - val_accuracy: 0.9582\n",
      "Epoch 10/30\n",
      "4640/4640 [==============================] - 1346s 290ms/step - loss: 0.1247 - accuracy: 0.9574 - val_loss: 0.1199 - val_accuracy: 0.9589\n",
      "Epoch 11/30\n",
      "4640/4640 [==============================] - 1339s 288ms/step - loss: 0.1214 - accuracy: 0.9584 - val_loss: 0.1157 - val_accuracy: 0.9604\n",
      "Epoch 12/30\n",
      "4640/4640 [==============================] - 1343s 290ms/step - loss: 0.1184 - accuracy: 0.9593 - val_loss: 0.1141 - val_accuracy: 0.9608\n",
      "Epoch 13/30\n",
      "4640/4640 [==============================] - 1340s 289ms/step - loss: 0.1157 - accuracy: 0.9602 - val_loss: 0.1120 - val_accuracy: 0.9615\n",
      "Epoch 14/30\n",
      "4640/4640 [==============================] - 1341s 289ms/step - loss: 0.1133 - accuracy: 0.9609 - val_loss: 0.1099 - val_accuracy: 0.9621\n",
      "Epoch 15/30\n",
      "4640/4640 [==============================] - 1340s 289ms/step - loss: 0.1110 - accuracy: 0.9617 - val_loss: 0.1071 - val_accuracy: 0.9631\n",
      "Epoch 16/30\n",
      "4640/4640 [==============================] - 1345s 290ms/step - loss: 0.1089 - accuracy: 0.9623 - val_loss: 0.1061 - val_accuracy: 0.9635\n",
      "Epoch 17/30\n",
      "4640/4640 [==============================] - 1345s 290ms/step - loss: 0.1068 - accuracy: 0.9630 - val_loss: 0.1052 - val_accuracy: 0.9637\n",
      "Epoch 18/30\n",
      "4640/4640 [==============================] - 1341s 289ms/step - loss: 0.1049 - accuracy: 0.9636 - val_loss: 0.1035 - val_accuracy: 0.9643\n",
      "Epoch 19/30\n",
      "4640/4640 [==============================] - 1339s 289ms/step - loss: 0.1033 - accuracy: 0.9641 - val_loss: 0.1021 - val_accuracy: 0.9648\n",
      "Epoch 20/30\n",
      "4640/4640 [==============================] - 1340s 289ms/step - loss: 0.1015 - accuracy: 0.9648 - val_loss: 0.1007 - val_accuracy: 0.9652\n",
      "Epoch 21/30\n",
      "4640/4640 [==============================] - 1342s 289ms/step - loss: 0.1000 - accuracy: 0.9653 - val_loss: 0.0995 - val_accuracy: 0.9655\n",
      "Epoch 22/30\n",
      "4640/4640 [==============================] - 1341s 289ms/step - loss: 0.0985 - accuracy: 0.9658 - val_loss: 0.0985 - val_accuracy: 0.9661\n",
      "Epoch 23/30\n",
      "4640/4640 [==============================] - 1345s 290ms/step - loss: 0.0972 - accuracy: 0.9662 - val_loss: 0.0969 - val_accuracy: 0.9665\n",
      "Epoch 24/30\n",
      "4640/4640 [==============================] - 1346s 290ms/step - loss: 0.0958 - accuracy: 0.9666 - val_loss: 0.0961 - val_accuracy: 0.9667\n",
      "Epoch 25/30\n",
      "4640/4640 [==============================] - 1342s 289ms/step - loss: 0.0945 - accuracy: 0.9671 - val_loss: 0.0950 - val_accuracy: 0.9672\n",
      "Epoch 26/30\n",
      "4640/4640 [==============================] - 1342s 289ms/step - loss: 0.0932 - accuracy: 0.9675 - val_loss: 0.0948 - val_accuracy: 0.9673\n",
      "Epoch 27/30\n",
      "4640/4640 [==============================] - 1345s 290ms/step - loss: 0.0921 - accuracy: 0.9679 - val_loss: 0.0934 - val_accuracy: 0.9677\n",
      "Epoch 28/30\n",
      "4640/4640 [==============================] - 1341s 289ms/step - loss: 0.0909 - accuracy: 0.9682 - val_loss: 0.0922 - val_accuracy: 0.9681\n",
      "Epoch 29/30\n",
      "4640/4640 [==============================] - 1337s 288ms/step - loss: 0.0898 - accuracy: 0.9686 - val_loss: 0.0920 - val_accuracy: 0.9680\n",
      "Epoch 30/30\n",
      "4640/4640 [==============================] - 1341s 289ms/step - loss: 0.0889 - accuracy: 0.9689 - val_loss: 0.0911 - val_accuracy: 0.9684\n"
     ]
    }
   ],
   "source": [
    "TrainingHistory = model.fit(\n",
    "    x=datagen,\n",
    "    epochs=Epochs,\n",
    "    verbose=1,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch = math.ceil(len(train_sample_paths)/BatchSize),\n",
    "    validation_steps = math.ceil(len(val_sample_paths)/BatchSize)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('../weights/model_weights_IR_16_1024.h5')\n",
    "#model.save_weights('../weights/model_weights_IR_64_2048.h5')\n",
    "model.save_weights('../weights/model_weights_xyzi_16_1024_GroundDetection_Epoch30.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate network general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('../weights/model_weights_xyzi_16_1024.h5')\n",
    "#model.load_weights('../weights/model_weights_IR_64_2048.h5')\n",
    "Evaluation = model.evaluate(eval_gen, steps=math.ceil(len(eval_sample_paths)/BatchSize))\n",
    "print(Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug - image creation\n",
    "## Evaluate network visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reduced model weights\n",
    "model.load_weights('../weights/model_weights_xyzi_16_1024_GroundDetection_inklTerain.h5')\n",
    "\n",
    "# Load full model weights\n",
    "#model.load_weights('../weights/model_weights_IR_64_2048.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictionToImage(Prediction):\n",
    "    # Map masterproject classes to kitti classes \n",
    "    Prediction = ProjectToKitti_LUT[Prediction]\n",
    "    # Map kitti classes to colors\n",
    "    Image = KittiToColor_LUT[Prediction]\n",
    "    Image = np.swapaxes(Image,0,1)\n",
    "    Image = Image[...,[2,1,0]]\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Define path of test PoinCloud\n",
    "TestPath = '/data/kitti_data/dataset/sequences'\n",
    "CurrentTestPoinCloudPath = TestPath + '/04/velodyne/000008.bin'\n",
    "\n",
    "# Create test PointCloud\n",
    "TestPointCloud = SemLaserScan(20, KittiToColorDict, project=True, W=2048, H=64)\n",
    "\n",
    "# Create full sample array from PoinCloud\n",
    "CurrentTestSampleFull = getSampleArrayFromPointCloud (TestPointCloud, CurrentTestPoinCloudPath)\n",
    "print(CurrentTestSampleFull.shape)\n",
    "#print(np.min(CurrentTestSampleFull[:,:,2]))\n",
    "CurrentTestSampleFull = np.expand_dims(CurrentTestSampleFull, axis=0)\n",
    "\n",
    "# Create reduced sample array from full sample array\n",
    "#print(CurrentTestSampleFull.shape)\n",
    "CurrentTestSampleReduced = CurrentTestSampleFull[0::,0::2,0::4]\n",
    "#print(np.min(CurrentTestSampleReduced[0,:,:,2]))\n",
    "#print(CurrentTestSampleReduced.shape)\n",
    "\n",
    "# Predict full PointCloud\n",
    "PredictionFull = model.predict(CurrentTestSampleFull)\n",
    "PredictionFull = np.argmax(PredictionFull,axis=3)\n",
    "PredictionFull = PredictionFull.squeeze()\n",
    "\n",
    "# Predict reduced PointCloud\n",
    "PredictionReduced = model.predict(CurrentTestSampleReduced)\n",
    "PredictionReduced = np.argmax(PredictionReduced,axis=3)\n",
    "PredictionReduced = PredictionReduced.squeeze()\n",
    "\n",
    "# Create images of predictions\n",
    "PredictionFullImage = PredictionToImage(PredictionFull)\n",
    "PredictionReducedImage = PredictionToImage(PredictionReduced)\n",
    "\n",
    "# [optional] Spot special classes in image\n",
    "#ids = np.where((CurrentTestSampleReduced[0,:,:,2] < -5))\n",
    "#print(ids)\n",
    "#PredictionReducedImage[ids] = [255, 0, 0]\n",
    "#PredictionReducedImage = np.swapaxes(PredictionReducedImage,0,1)\n",
    "#PredictionFullImage = np.swapaxes(PredictionFullImage,0,1)\n",
    "\n",
    "# Show and save full prediction image\n",
    "fig = plt.figure()\n",
    "plt.imshow(PredictionFullImage)\n",
    "plt.show\n",
    "plt.imsave('../images/PredictionFull.png', PredictionFullImage)\n",
    "\n",
    "# Show and save reduced prediction image\n",
    "fig = plt.figure()\n",
    "plt.imshow(PredictionReducedImage)\n",
    "plt.show\n",
    "plt.imsave('../images/PredictionReduced.png', PredictionReducedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentTestLabelPath = TestPath + '/04/labels/000008.label'\n",
    "\n",
    "CurrentLabelFull = getLabelArrayFromPointCloud (TestPointCloud, CurrentTestLabelPath)\n",
    "CurrentLabelFull = np.expand_dims(CurrentLabelFull, axis=0)\n",
    "\n",
    "CurrentLabelReduced = CurrentLabelFull[0::,0::2,0::4]\n",
    "\n",
    "CurrentLabelFull = np.argmax(CurrentLabelFull,axis=3)\n",
    "CurrentLabelFull = CurrentLabelFull.squeeze()\n",
    "\n",
    "CurrentLabelReduced = np.argmax(CurrentLabelReduced,axis=3)\n",
    "CurrentLabelReduced = CurrentLabelReduced.squeeze()\n",
    "\n",
    "GroundTruthFullImage = PredictionToImage(CurrentLabelFull)\n",
    "GroundTruthReducedImage = PredictionToImage(CurrentLabelReduced)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(GroundTruthFullImage)\n",
    "plt.show\n",
    "plt.imsave('../images/GroundTruthFullImage.png', GroundTruthFullImage)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(GroundTruthReducedImage)\n",
    "plt.show\n",
    "plt.imsave('../images/GroundTruthReducedImage.png', GroundTruthReducedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create intensity histogram of full kitti data\n",
    "fig = plt.figure()\n",
    "print(CurrentTestSampleFull.shape)\n",
    "I = CurrentTestSampleFull[:,:,:,0].flatten()\n",
    "# print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')\n",
    "plt.title(\"Intensity histogram of full kitti data\")\n",
    "plt.show()\n",
    "\n",
    "# Create intensity histogram of reduced kitti data\n",
    "fig = plt.figure()\n",
    "I = CurrentTestSampleReduced[:,:,:,0].flatten()\n",
    "print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Intensity histogram of reduced kitti data\")\n",
    "plt.show()\n",
    "\n",
    "# Create range histogram of full kitti data\n",
    "fig = plt.figure()\n",
    "print(CurrentTestSampleFull.shape)\n",
    "I = CurrentTestSampleFull[:,:,:,1].flatten()\n",
    "# print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')\n",
    "plt.title(\"Range histogram of full kitti data\")\n",
    "plt.show()\n",
    "\n",
    "# Create range histogram of reduced kitti data\n",
    "fig = plt.figure()\n",
    "I = CurrentTestSampleReduced[:,:,:,1].flatten()\n",
    "print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Range histogram of reduced kitti data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict BugaLog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCDPATH = '../data/pcd_files/'\n",
    "current_pcd_path = PCDPATH + 'front_cloud_straße.pcd' #'top_cloud_git.pcd'\n",
    "\n",
    "PointCloud = SemLaserScan(20, KittiToColorDict, project=True, W=1440, H=16, fov_up=15, fov_down=-15.0)\n",
    "\n",
    "current_sample = getSampleArrayFromPointCloud_pcd(PointCloud, current_pcd_path, 1.13)\n",
    "#print(current_sample.shape)\n",
    "#current_sample[:,:,2] = current_sample[:,:,2] -0.4#1.13 #+0.7 #- 1.13\n",
    "print(np.max(current_sample[:,:,2]))\n",
    "print(np.min(current_sample[:,:,2]))\n",
    "\n",
    "#current_sample = current_pcd\n",
    "current_sample = np.expand_dims(current_sample, axis=0)\n",
    "\n",
    "#current_sample = current_sample[0::,0::2,0::4]\n",
    "#current_sample[np.where(current_sample[:,:,:,0] > 0.4)] = [-1, -1]\n",
    "\n",
    "Prediction = model.predict(current_sample)\n",
    "\n",
    "Prediction = np.argmax(Prediction,axis=3)\n",
    "\n",
    "Prediction = Prediction.squeeze()\n",
    "\n",
    "BugaLogImage = PredictionToImage(Prediction)\n",
    "\n",
    "plt.imshow(BugaLogImage)\n",
    "plt.show\n",
    "plt.imsave('../images/BugaLogImage.png', BugaLogImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "I = current_sample[:,:,:,0].flatten()\n",
    "print(I.shape)\n",
    "hist = plt.hist(I, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Intensity histogram of buga log data\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "R = current_sample[:,:,:,1].flatten()\n",
    "print(R.shape)\n",
    "hist = plt.hist(R, bins='auto')  # arguments are passed to np.histogram\n",
    "plt.title(\"Range histogram of buga log data\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
